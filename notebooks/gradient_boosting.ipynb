{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab73bf1a",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f04b9",
   "metadata": {},
   "source": [
    "Градиентный спуск (Gradient Descent)\n",
    "\n",
    "Это метод оптимизации: ты берёшь параметры одной модели (например, веса нейросети) и двигаешься по градиенту вниз, чтобы уменьшить ошибку.\n",
    "\n",
    "Ассоциация: спуск с горы — каждый шаг ты делаешь туда, где “ниже” (меньше loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42587efe",
   "metadata": {},
   "source": [
    "# Градиентный спуск "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd31ab8",
   "metadata": {},
   "source": [
    "Градиентный бустинг\n",
    "\n",
    "Это модель/алгоритм ансамбля, который тоже использует идею градиента, но не по весам одной модели, а в “пространстве функций”: мы добавляем новые деревья как “маленькие поправки”, уменьшающие loss. Это классическое описание у Фридмана.\n",
    "\n",
    "Ассоциация:\n",
    "представь, что ты пишешь текст, а потом его по очереди правят 100 редакторов.\n",
    "1-й редактор исправил очевидные ошибки, 2-й — то, что осталось, 3-й — ещё тоньше… В итоге получается сильный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ea893",
   "metadata": {},
   "source": [
    "# Отличие бустинга от спуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9ba1f",
   "metadata": {},
   "source": [
    "мы строим не одну “большую умную” модель, а ансамбль из многих простых моделей (обычно небольших деревьев).\n",
    "Модели добавляются по очереди: каждая новая пытается исправить ошибки предыдущих."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cfe57",
   "metadata": {},
   "source": [
    "XGBoost и CatBoost библиотеки которые осущ град бустинг на деревьях"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396d5f0",
   "metadata": {},
   "source": [
    "больше инфы: \n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "Это библиотека, которая “делает градиентный бустинг на деревьях” очень эффективно (скорость/оптимизации/масштабирование). В их документации прямо сказано, что XGBoost — это “optimized distributed gradient boosting library”, и что это бустинг в рамках Gradient Boosting framework.\n",
    "\n",
    "Ассоциация: “градиентный бустинг на стероидах” — тот же алгоритм по идее, но очень круто оптимизированный.\n",
    "\n",
    "**CatBoost**\n",
    "\n",
    "Это тоже градиентный бустинг на деревьях, но сделанный так, чтобы очень хорошо работать с категориальными признаками (типа “город”, “пол”, “профессия”) и уменьшать переобучение/утечки при их обработке. Это прямо заявлено в их статье и документации.\n",
    "\n",
    "Ассоциация: XGBoost = “быстрый мощный бустинг”, CatBoost = “бустинг, который особенно удобен, когда много категорий”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d7ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:212: RuntimeWarning: divide by zero encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:212: RuntimeWarning: overflow encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:212: RuntimeWarning: invalid value encountered in matmul\n",
      "  norm2_w = weights @ weights if weights.ndim == 1 else squared_norm(weights)\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline(LogReg) ===\n",
      "Accuracy: 0.9504\n",
      "F1 weighted: 0.9502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9515    0.9691    0.9602       162\n",
      "           1     0.9485    0.9200    0.9340       100\n",
      "\n",
      "    accuracy                         0.9504       262\n",
      "   macro avg     0.9500    0.9446    0.9471       262\n",
      "weighted avg     0.9503    0.9504    0.9502       262\n",
      "\n",
      "\n",
      "=== GradientBoosting(HistGB) ===\n",
      "Accuracy: 0.9466\n",
      "F1 weighted: 0.9463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9458    0.9691    0.9573       162\n",
      "           1     0.9479    0.9100    0.9286       100\n",
      "\n",
      "    accuracy                         0.9466       262\n",
      "   macro avg     0.9468    0.9396    0.9429       262\n",
      "weighted avg     0.9466    0.9466    0.9463       262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/utils/extmath.py:227: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "# 1) Загружаем Titanic (OpenML)\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "\n",
    "# y может быть строками ('0'/'1') — приведём к int 0/1\n",
    "y = y.astype(int)\n",
    "\n",
    "# 2) Разделим на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) Препроцессинг: числовые и категориальные колонки\n",
    "num_cols = X_train.select_dtypes(include=[\"number\"]).columns\n",
    "cat_cols = X_train.select_dtypes(exclude=[\"number\"]).columns\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 4) Baseline: Logistic Regression\n",
    "baseline = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "# 5) Gradient Boosting (быстрый вариант в sklearn)\n",
    "gb = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        max_iter=400,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 6) Обучаем\n",
    "baseline.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# 7) Оцениваем\n",
    "for name, model in [(\"Baseline(LogReg)\", baseline), (\"GradientBoosting(HistGB)\", gb)]:\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1w = f1_score(y_test, pred, average=\"weighted\")\n",
    "    print(\"\\n===\", name, \"===\")\n",
    "    print(\"Accuracy:\", round(acc, 4))\n",
    "    print(\"F1 weighted:\", round(f1w, 4))\n",
    "    print(classification_report(y_test, pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5efaa4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_names: []\n",
      "columns: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
      "\n",
      "=== Baseline(LogReg) ===\n",
      "Accuracy: 0.8033\n",
      "F1 weighted: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8636    0.6786    0.7600        28\n",
      "           1     0.7692    0.9091    0.8333        33\n",
      "\n",
      "    accuracy                         0.8033        61\n",
      "   macro avg     0.8164    0.7938    0.7967        61\n",
      "weighted avg     0.8126    0.8033    0.7997        61\n",
      "\n",
      "\n",
      "=== GradientBoosting(HistGB) ===\n",
      "Accuracy: 0.8197\n",
      "F1 weighted: 0.8172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8696    0.7143    0.7843        28\n",
      "           1     0.7895    0.9091    0.8451        33\n",
      "\n",
      "    accuracy                         0.8197        61\n",
      "   macro avg     0.8295    0.8117    0.8147        61\n",
      "weighted avg     0.8262    0.8197    0.8172        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/mariaburtseva/Documents/проект грант/slr-env/.venv/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:333: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\"\"\"\n",
    "#загружаем датасет сердце с опенМЛ\n",
    "X, y = fetch_openml(\"heart-disease\", version=1, as_frame=True, return_X_y = True)\n",
    "\n",
    "#типируем все значения метки как инт\n",
    "y = y.astype(int)\n",
    "\"\"\"\n",
    "#загружем датасет\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = fetch_openml(\"heart-disease\", version=1, as_frame=True)  # БЕЗ return_X_y\n",
    "df = data.frame  # тут уже X + y в одной таблице\n",
    "\n",
    "print(\"target_names:\", data.target_names)\n",
    "print(\"columns:\", df.columns.tolist())\n",
    "\n",
    "# выбираем колонку-таргет (часто она называется \"class\")\n",
    "target_col = None\n",
    "\n",
    "if data.target_names:\n",
    "    for t in data.target_names:\n",
    "        if t in df.columns:\n",
    "            target_col = t\n",
    "            break\n",
    "\n",
    "if target_col is None:\n",
    "    candidates = [\"target\", \"num\", \"class\", \"label\", \"y\", \"diagnosis\", \"outcome\"]\n",
    "    col_map = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c.lower() in col_map:\n",
    "            target_col = col_map[c.lower()]\n",
    "            break\n",
    "\n",
    "if target_col is None and getattr(data, \"target\", None) is not None:\n",
    "    y = pd.Series(data.target)\n",
    "    X = df\n",
    "else:\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col])\n",
    "\n",
    "# превращаем y в 0/1\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(pd.Series(y).astype(str).str.strip())\n",
    "\n",
    "\n",
    "\n",
    "#разделяем данные на трейн и тест\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42, stratify=y\n",
    ")\n",
    "\n",
    "#разделяем колонки с числами и с признаками\n",
    "num_cols = X_train.select_dtypes(include = [\"number\"]).columns\n",
    "cat_cols = X_train.select_dtypes(exclude = [\"number\"]).columns\n",
    "\n",
    "#если не находим нужное число заменяем на стреднее (крч фильтр грубо говоря)\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy = \"median\"))\n",
    "])\n",
    "\n",
    "#если не находим нужный признак то заменяем на самый частый прзнак \n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "#теперь пропускаем все числа/признаки через фильтры для них\n",
    "# готовим данные к модельки, фильтруем их/проверяем, (заполнение пропусков + one-hot)\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# модель 1: лог регрессия, предсказание метрики\n",
    "baseline = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000)) #классификатор\n",
    "])\n",
    "\n",
    "#модель 2: град бустинг\n",
    "gb = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        max_iter=400,\n",
    "        early_stopping=True,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#обучение модели\n",
    "baseline.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "#сравниваем результаты двух моделек: гб и регрессия\n",
    "for name, model in [(\"Baseline(LogReg)\", baseline), (\"GradientBoosting(HistGB)\", gb)]:\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1w = f1_score(y_test, pred, average=\"weighted\")\n",
    "    print(\"\\n===\", name, \"===\")\n",
    "    print(\"Accuracy:\", round(acc, 4))\n",
    "    print(\"F1 weighted:\", round(f1w, 4))\n",
    "    print(classification_report(y_test, pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9870ba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.target_names = []\n",
      "df columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n"
     ]
    }
   ],
   "source": [
    "data = fetch_openml(\"heart-disease\", version=1, as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "print(\"data.target_names =\", data.target_names)\n",
    "print(\"df columns =\", df.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
